# LLM provider credentials and endpoint
MODEL_API_KEY=
MODEL_BASE_URL=https://api.deepseek.com
LLM_MODEL=deepseek-chat

# Embedding provider credentials and endpoint
EMBEDDING_API_KEY=
EMBEDDING_BASE_URL=https://api.openai.com/v1/
EMBEDDING_MODEL=text-embedding-3-large
# Must match the embedding model output dimension used for vector indexes.
EMBEDDING_DIM=3072

# Neo4j ports exposed by docker-compose
NEO4J_BROWSER_PORT=7475
NEO4J_BOLT_PORT=7688

# Admin credentials used by scripts/ingest and entrypoint
TKG_NEO4J_USER=neo4j
TKG_NEO4J_PASSWORD=passworty

# Bolt URI used by clients outside the container
NEO4J_URI=bolt://localhost:7688

# Deduplication threshold for entity alias BM25 + IoU filtering
ENTITY_DEDUP_SCORE=0.9
